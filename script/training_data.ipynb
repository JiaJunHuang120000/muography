{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46651aa9-b41c-42a9-aa60-bd5be07c2efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, uproot as ur, awkward as ak, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os, sys\n",
    "import pickle\n",
    "import uproot\n",
    "import fnmatch\n",
    "import mplhep as hep\n",
    "plt.figure()\n",
    "hep.style.use(\"CMS\")\n",
    "plt.close()\n",
    "\n",
    "def gaus(x, amp, mean, sigma):\n",
    "    return amp * np.exp( -(x - mean)**2 / (2*sigma**2) ) \n",
    "\n",
    "def phi_reconstruct(x, y, z):\n",
    "    return np.degrees(np.arctan2(y, x))\n",
    "    \n",
    "def theta_reconstruct(x, y, z):\n",
    "    return np.degrees(np.arccos(abs(z)/np.sqrt(x**2+y**2+z**2)))\n",
    "\n",
    "def vector_angle_reconstruct(x, y, z):\n",
    "    data = np.concatenate((np.array(x)[:, np.newaxis], \n",
    "                           np.array(y)[:, np.newaxis], \n",
    "                           np.array(z)[:, np.newaxis]), \n",
    "                          axis=1)\n",
    "    datamean = data.mean(axis=0)\n",
    "    centered_data = data - datamean\n",
    "\n",
    "    _, _, vv = np.linalg.svd(centered_data)\n",
    "    direction_vector = vv[0]\n",
    "    if direction_vector[2] > 0:\n",
    "        direction_vector *= -1\n",
    "        \n",
    "    x_vec, y_vec, z_vec = direction_vector\n",
    "    \n",
    "    theta = theta_reconstruct(x_vec, y_vec, z_vec)\n",
    "    phi = phi_reconstruct(x_vec, y_vec, z_vec)\n",
    "    \n",
    "    return theta, phi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "41c3a40d-5630-4296-bddf-3ad041e5f5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doneessing four_detector_free_3_1.root 8/10: 1/2202133\n"
     ]
    }
   ],
   "source": [
    "#files = sorted(os.listdir(f'../muography/data/'))\n",
    "target_files = fnmatch.filter(files, \"four_detector_target_*_1.root\")\n",
    "free_files   = fnmatch.filter(files, \"four_detector_free_*_1.root\")\n",
    "files = np.concatenate([target_files,free_files])\n",
    "for j, file in enumerate(files):\n",
    "    if 'merge' in file: continue\n",
    "    with ur.open('~/muography/data/'+file+\":events\") as f:\n",
    "        arrays = f.arrays(filter_name=[\"MuographyHits.energy\", \"MuographyHitsContributions.time\", \"MuographyHits.position.x\", \"MuographyHits.position.y\", \"MuographyHits.position.z\", \"MCParticles.PDG\", \"MCParticles.generatorStatus\", \"MCParticles.momentum.x\", \"MCParticles.momentum.y\", \"MCParticles.momentum.z\", \"MCParticles.vertex.x\", \"MCParticles.vertex.y\", \"MCParticles.vertex.z\", \"MCParticles.mass\"])\n",
    "\n",
    "    y,x=np.histogram(ak.flatten(arrays[\"MuographyHits.energy\"]), bins=100, range=(0, 0.004))\n",
    "    bc=(x[1:]+x[:-1])/2\n",
    "    MIP=list(bc[y==max(y)])[0] \n",
    "    plt.errorbar(np.array(bc)*1000,np.array(y),yerr=np.sqrt(y))\n",
    "    plt.axvline(0.2*MIP*1000,label=f'MIP = {MIP*1000:.2f} MeV')\n",
    "    plt.xlabel('Cell Energy (MeV)')\n",
    "    plt.legend()\n",
    "    plt.close()\n",
    "    \n",
    "    data_energy = arrays[f'MuographyHits.energy']\n",
    "    \n",
    "    sigma = 0.56\n",
    "    \n",
    "    # flatten to numpy\n",
    "    flat = ak.to_numpy(data_energy.layout.content)\n",
    "    noise = np.random.normal(0, sigma, size=len(flat))*MIP\n",
    "    \n",
    "    # add noise\n",
    "    flat_smear = np.clip(flat + noise, a_min=1e-16, a_max=None)\n",
    "    \n",
    "    # rebuild jagged array\n",
    "    offsets = ak.to_numpy(data_energy.layout.offsets)  # convert Index64 â†’ numpy\n",
    "    lengths = offsets[1:] - offsets[:-1]\n",
    "    data_energy_smear = ak.unflatten(flat_smear, lengths)\n",
    "    \n",
    "    data_MIP_cut = data_energy_smear > 0.2*MIP\n",
    "    data_cell_cut = ak.num(arrays[f'MuographyHits.energy'], axis=1) >= 2\n",
    "\n",
    "    data_energy = data_energy[np.array(data_cell_cut)]\n",
    "    data_energy_smear = data_energy_smear[np.array(data_cell_cut)]\n",
    "    data_x = arrays[f'MuographyHits.position.x'][np.array(data_cell_cut)]\n",
    "    data_y = arrays[f'MuographyHits.position.y'][np.array(data_cell_cut)]\n",
    "    data_z = arrays[f'MuographyHits.position.z'][np.array(data_cell_cut)]    \n",
    "    reco_data_angle = np.array([vector_angle_reconstruct(np.array(xi,dtype=float), np.array(yi,dtype=float), np.array(zi,dtype=float)) for xi, yi, zi in zip(data_x,data_y,data_z)])\n",
    "    data_theta = ak.Array(reco_data_angle[:,0])\n",
    "    data_phi = ak.Array(reco_data_angle[:,1])\n",
    "    status = arrays[\"MCParticles.generatorStatus\"]\n",
    "    mc_px = arrays[\"MCParticles.momentum.x\"][status==1][np.array(data_cell_cut)]\n",
    "    mc_py = arrays[\"MCParticles.momentum.y\"][status==1][np.array(data_cell_cut)]\n",
    "    mc_pz = arrays[\"MCParticles.momentum.z\"][status==1][np.array(data_cell_cut)]\n",
    "    mc_theta = theta_reconstruct(mc_px,mc_py,mc_pz)\n",
    "    mc_phi = phi_reconstruct(mc_px,mc_py,mc_pz)\n",
    "    mc_PDG = arrays[\"MCParticles.PDG\"][status==1][np.array(data_cell_cut)]\n",
    "    mc_mass = arrays[\"MCParticles.mass\"][status==1][np.array(data_cell_cut)]\n",
    "    \n",
    "    data_time = arrays[\"MuographyHitsContributions.time\"][np.array(data_cell_cut)]\n",
    "    status = status[status==1][np.array(data_cell_cut)]\n",
    "    num = 10000\n",
    "    for i in range(int(len(mc_theta)/num)):\n",
    "        print(f\"Processing {file} {j}/{len(files)}: {i}/{int(len(mc_theta)/num)-1}\", end='\\r',flush=True)\n",
    "        branches = {\n",
    "            \"MuographyHits.position.x\": data_x[i*num:(i+1)*num],\n",
    "            \"MuographyHits.position.y\": data_y[i*num:(i+1)*num],\n",
    "            \"MuographyHits.position.z\": data_z[i*num:(i+1)*num],\n",
    "            \"MuographyHits.energy_nonsmear\": data_energy[i*num:(i+1)*num],\n",
    "            \"MuographyHits.energy\": data_energy_smear[i*num:(i+1)*num],\n",
    "            \"MuographyHits.time\": data_time[i*num:(i+1)*num],\n",
    "            \"MuographyHits.theta\": data_theta[i*num:(i+1)*num],\n",
    "            \"MuographyHits.phi\": data_phi[i*num:(i+1)*num], \n",
    "            \"MCParticles.theta\": mc_theta[i*num:(i+1)*num],\n",
    "            \"MCParticles.phi\": mc_phi[i*num:(i+1)*num],\n",
    "            \"MCParticles.generatorStatus\": status[i*num:(i+1)*num],\n",
    "            \"MCParticles.PDG\": mc_PDG[i*num:(i+1)*num],\n",
    "            \"MCParticles.mass\": mc_mass[i*num:(i+1)*num],\n",
    "            \"MCParticles.momentum.x\": mc_px[i*num:(i+1)*num],\n",
    "            \"MCParticles.momentum.y\": mc_py[i*num:(i+1)*num],\n",
    "            \"MCParticles.momentum.z\": mc_pz[i*num:(i+1)*num]\n",
    "        }\n",
    "        \n",
    "        \n",
    "        with uproot.recreate(f'training/128_channel_test/{file}_{i}.root') as fout:\n",
    "            fout[\"events\"] = branches\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a170a181-1179-4a93-8229-c7d3d637f569",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63b9297-7784-43aa-b0b6-ec241df34467",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "843e36b9-96d7-415b-b0fd-2184bf2b8ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_result = \"data/training/128_channel_test\"\n",
    "npz_unpacked = np.load(path_to_result+\"/predictions_appended_test.npz\", allow_pickle=True) \n",
    "\n",
    "predictions_unnormalized = npz_unpacked['outputs_scaled'].item()\n",
    "targets_unnormalized = npz_unpacked['targets_scaled'].item()\n",
    "predictions = npz_unpacked['outputs'].item()\n",
    "targets = npz_unpacked['targets'].item()\n",
    "meta = npz_unpacked['meta']\n",
    "predictions_theta = np.degrees(predictions_unnormalized[\"theta\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "abd09dd3-50b1-4cd9-9046-b4a1dc8a84ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: square_offset_rotated_109.root\n",
      "Processing: square_offset_rotated_104.root\n",
      "Processing: square_offset_rotated_94.root\n",
      "Processing: square_offset_rotated_103.root\n",
      "Processing: square_offset_rotated_91.root\n",
      "Processing: square_offset_rotated_82.root\n",
      "Processing: square_offset_rotated_101.root\n",
      "Processing: square_offset_rotated_111.root\n",
      "Processing: square_offset_rotated_110.root\n",
      "Processing: square_offset_rotated_102.root\n",
      "Processing: square_offset_rotated_107.root\n",
      "Processing: square_offset_rotated_105.root\n",
      "Processing: square_offset_rotated_106.root\n",
      "Processing: square_offset_rotated_97.root\n",
      "Processing: square_offset_rotated_88.root\n",
      "Processing: square_offset_rotated_85.root\n",
      "Processing: square_offset_rotated_79.root\n",
      "Processing: square_offset_rotated_100.root\n",
      "Processing: square_offset_rotated_99.root\n",
      "Processing: square_offset_rotated_87.root\n",
      "Processing: square_offset_rotated_81.root\n",
      "Processing: square_offset_rotated_98.root\n",
      "Processing: square_offset_rotated_83.root\n",
      "Processing: square_offset_rotated_84.root\n",
      "Processing: square_offset_rotated_93.root\n",
      "Processing: square_offset_rotated_90.root\n",
      "Processing: square_offset_rotated_96.root\n",
      "Processing: square_offset_rotated_78.root\n",
      "Processing: square_offset_rotated_80.root\n",
      "Processing: square_offset_rotated_86.root\n",
      "Processing: square_offset_rotated_108.root\n",
      "Processing: square_offset_rotated_95.root\n",
      "Processing: square_offset_rotated_92.root\n",
      "Processing: square_offset_rotated_89.root\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import awkward as ak\n",
    "import uproot as ur\n",
    "\n",
    "files = os.listdir('training/test_data1/')\n",
    "merged = None  # will hold concatenated dataset\n",
    "\n",
    "for i, file in enumerate(files):\n",
    "    with ur.open(f'training/test_data1/{file}:events') as f:\n",
    "        arrays = f.arrays([\n",
    "            \"MuographyHits.energy\", \n",
    "            \"MuographyHits.theta\", \n",
    "            \"MuographyHits.phi\", \n",
    "            \"MCParticles.theta\", \n",
    "            \"MCParticles.phi\"\n",
    "        ])\n",
    "\n",
    "    print(f'Processing: {file}')\n",
    "\n",
    "    cut = [file in i for i in meta[:, 0]]\n",
    "    arrays[\"GNN.theta\"] = predictions_theta[cut]\n",
    "\n",
    "    branches = {\n",
    "        \"MuographyHits.energy\": ak.sum(arrays[\"MuographyHits.energy\"], axis=-1),\n",
    "        \"MuographyHits.theta\": arrays[\"MuographyHits.theta\"],\n",
    "        \"MuographyHits.phi\": arrays[\"MuographyHits.phi\"],\n",
    "        \"MCParticles.theta\": ak.flatten(arrays[\"MCParticles.theta\"]),\n",
    "        \"MCParticles.phi\": ak.flatten(arrays[\"MCParticles.phi\"]),\n",
    "        \"GNN.theta\": ak.flatten(arrays[\"GNN.theta\"]),\n",
    "    }\n",
    "\n",
    "    # Wrap dict into an Awkward record array\n",
    "    batch = ak.Array(branches)\n",
    "\n",
    "    # Concatenate across files\n",
    "    merged = batch if merged is None else ak.concatenate([merged, batch], axis=0)\n",
    "\n",
    "# Save once at the end\n",
    "with open(\"data/training/merge.pkl\", \"wb\") as fout:\n",
    "    pickle.dump(merged, fout)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
